{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Gradient Descent</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Import Pylab\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's revisit our Neural Network class and reexamine our results.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        #Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        \n",
    "        #Synaptic Weights\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propagate inputs feed forward through our network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3)\n",
    "        return yHat\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function\n",
    "        return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Input Data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(([3,5], [5,1], [10,2]), dtype=float)\n",
    "y = np.array(([75], [82], [93]), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100 #Max test score is 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p>Feed Forward pass of input data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NN = NeuralNetwork()\n",
    "yHat = NN.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3,  1. ],\n",
       "       [ 0.5,  0.2],\n",
       "       [ 1. ,  0.4]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75],\n",
       "       [ 0.82],\n",
       "       [ 0.93]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p>By comparing yHat to y, we can see how wrong our predictions are when we use random values for the synaptic weights.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77298086],\n",
       "       [ 0.6727637 ],\n",
       "       [ 0.65468556]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p>To visualize how poorly our synaptic weights are making our predictions, we can use ipython's built in matplotlib interface and graph our predicted results versus the actual results. Another term for this difference in prediction is the cost.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcfb07e9cf8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAhtk/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcfb07e95c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar([0,1,2], y, width = 0.35, alpha=0.8)\n",
    "bar([0.35,1.35,2.35],yHat, width = 0.35, color='r', alpha=0.8)\n",
    "grid(1)\n",
    "legend(['y', 'yHat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p>Humans do not just think feed forward. Although feed forward networks are good for making decisions, and the perceptron model can get as advanced as NAND gates (as some research into circuits will show), they do not correct themselves when they make incorrect decisions. This is the problem with our network.</p>\n",
    "<br>\n",
    "<p>Imagine it is wintertime, and you need to drive to class in an old car. Before your car can run you must warm up the engine and the cold oil, allowing it to disperse around your car's inner mechanics. Each time you drive to class you are going to try a random value for time to warm up your car. The synaptic weight you apply to that time for it's quantification of success would be similar to the weights in our scenario. Eventually, we will devise a way to test some random values, find the best random value, and simulate learning. Right now, using our neural network, sometimes we would choose the right value for time, and sometimes we would not, and we would not account for error. The goal of this week's journal is to find a way to quantify this error. We will visit how to train the network in Week 4's journal.</p>\n",
    "<br>\n",
    "<p>Our data is dependent upon the input values X and y, and the synaptic weights. When we run our network feed forward on X, we can use the predicted results, yHat and y to analyze the error, or \"cost\" of our values for W. This function can be expressed as J=(y-yHat), where J is the cost. This function is good, but let's modify it somewhat. Later in this journal series, we will analyze why we chose this cost function, but for now, let us set J=1/2(y-yHat)<sup>2</sup>. Additionally, we have many synaptic weights, and we need to test all 9 of our values for W, so our function becomes: J = &Sigma;1/2(y-yHat)<sup>2</sup>.</p>\n",
    "<br>\n",
    "<p>As Stephen Welch states, \"When someone refers to training a network, what they really mean is minimizing a cost function.\"</p>\n",
    "<br>\n",
    "<p>Now that we know our goal, we need to simply adjust values of W to minimize our cost function. How long does this take however? Let's explore that question using Python's time class on just one synaptic weight for 1000 random values for W.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "weightsToTry = np.linspace(-5,5,1000)\n",
    "costs = np.zeros(1000)\n",
    "\n",
    "startTime = time.clock()\n",
    "for i in range(1000):\n",
    "    NN.W1[0,0] = weightsToTry[i]\n",
    "    yHat = NN.forward(X)\n",
    "    costs[i] = 0.5*sum((y-yHat)**2)\n",
    "    \n",
    "endTime = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03247300000000308"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeElapsed = endTime-startTime\n",
    "timeElapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p>If we entertain the idea that the above result of about .3 seconds is reasonable, we can just plot our weights and the cost and pick the smallest value.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fcfb06cfdd8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEPCAYAAAC3NDh4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKhIiIpLX/wdhESh1hTiO7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcfafebe940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(weightsToTry, costs)\n",
    "grid(1)\n",
    "ylabel('Cost')\n",
    "xlabel('Weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p>We have indeed successfully minimized our cost function in terms of one synaptic weight, however, lets see how long it takes to simply try 1000 random values for 2 weights...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weightsToTry = np.linspace(-5,5,1000)\n",
    "costs = np.zeros((1000, 1000))\n",
    "\n",
    "startTime = time.clock()\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        NN.W1[0,0] = weightsToTry[i]\n",
    "        NN.W1[0,1] = weightsToTry[j]\n",
    "        yHat = NN.forward(X)\n",
    "        costs[i, j] = 0.5*sum((y-yHat)**2)\n",
    "    \n",
    "endTime = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.194325"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeElapsed = endTime-startTime\n",
    "timeElapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p>Ouch, that is starting to take some time. This is due to dimensionality, as demonstrated by the calculation below which shows how long it would take to check 9 weights for 1000 random values. The answer is more than the time since the birth of the universe, so let's try and find a better way to minimize our cost function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268391679350583.5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.04*(1000**(9-1))/(3600*24*365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>So far, our network takes some normalized input matrix, X and multiplies it by our first layer of synaptic weights W<sup>1</sup> to get matrix Z<sup>2</sup>. Next, this matrix is multiplied by our activation function, f(Z<sup>2</sup>) to get matrix a<sup>2</sup>. a<sup>2</sup> is multiplied by the second layer of synaptic weights W<sup>2</sup> to find Z<sup>3</sup>, and finally we apply our activation function to Z<sup>3</sup> to find yHat, our predicted test scores.</p>\n",
    "<br>\n",
    "<h4>Equations</h4>\n",
    "<li>1. Z<sup>(2)</sup> = XW<sup>(1)</sup></li>\n",
    "<li>2. a<sup>(2)</sup> = f( Z<sup>(2)</sup> )</li>\n",
    "<li>3. Z<sup>(3)</sup> = a<sup>(2)</sup>W<sup>(2)</sup></li>\n",
    "<li>4. yHat = f( Z<sup>(3)</sup> )\n",
    "<p>Additionally, we found that if we change the values for the weights, it has an effect on the output yHat. More specifically, if we create an equation for the difference between yHat and y, or a cost function J, we can quantify how wrong our predictions are and adjust the synaptic weights accordingly. We chose this cost function to be J = &Sigma;(1/2(y - yHat)<sup>2</sup>). By choosing the correct combination of synaptic weights we can minimize the cost function and ensure we are making the best possible predictions. Now our list of equations becomes...</p>\n",
    "<br>\n",
    "<h4>Equations</h4>\n",
    "<li>1. Z<sup>(2)</sup> = XW<sup>(1)</sup></li>\n",
    "<li>2. a<sup>(2)</sup> = f( Z<sup>(2)</sup> )</li>\n",
    "<li>3. Z<sup>(3)</sup> = a<sup>(2)</sup>W<sup>(2)</sup></li>\n",
    "<li>4. yHat = f( Z<sup>(3)</sup> )\n",
    "<li>5. J = &Sigma;(1/2(y - yHat)<sup>2</sup>)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's rewrite our equations in terms of our cost function, J.</p>\n",
    "<br>\n",
    "<p>J = &Sigma; 1/2( y - f( f( XW<sup>(1)</sup> ) W<sup>(2)</sup> ) )<sup>2</sup>\n",
    "<br>\n",
    "<br>\n",
    "<li>J is dependent on our input matrix X, our input results y, the feed forward prediction matrix yHat, and the two synaptic weight matrices W<sup>(1)</sup> and W<sup>(2)</sup>.</li></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We have no control over our input data, as that is a model of real life information and if manipulated, would manipulate our results. What we do have to work with are our weights. If we can find how J changes in respect to W<sup>(1)</sup> and W<sup>(2)</sup>, or in other words the partial derivative of J in terms of W, or &part;J/&part;W<sup>(1)</sup> and &part;J/&part;W<sup>(2)</sup>, we can find where our function is going downhill.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can increase or decrease W<sup>(1)</sup> and W<sup>(2)</sup> and observe it's effect on our partial derivatives. If they are increasing we know that the rate of change is positive, and similarly if they are negative, the rate of change is decreasing. If we iteratively repeat this process until the partial derivatives stop decreasing, then we have reached the minimum of our cost function and have completed our objective; or in other words have found a combination of synaptic weights that minimizes the cost.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"gradientDescent.png\" width = \"400\" align = \"left\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href = \"http://i.stack.imgur.com/xJgdz.png\">-source</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This is the core idea of Gradient Descent. We have a function and we find where the slope of that function is at a minimum, or zero. This value corresponds to the best possible synaptic weights for that synapse. The next step in our Neural Network is Backpropagation, so now we will need to derive values for &part;J/&part;W<sup>(1)</sup> and &part;J/&part;W<sup>(2)</sup></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>*It is important to now bring up why we chose our cost function to be the sum of squared errors. If you examine the graph above, it is very clear to see where the minimum is, however observe the graph below.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"localMin.gif\" width = \"400\" align = \"left\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href = \"http://borisv.lk.net/matsc597c-1997/introduction/Lecture5/img44.gif\">-source</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As you can see, there is still a possibility that gradient descent will find a local minimum rather than the necessary global minimum. Luckily for us, the sum of squared errors function is naturally convex, and is naturally convex for really high dimensions as well, which is good for us considering our optimization space is 9 dimensional!</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
