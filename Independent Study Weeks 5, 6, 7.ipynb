{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MNIST and Neural Nets in Practice</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>There are many factors that determine how a neural network will function. One of these factors is your computer. Because neural networks are a mix of brute force and finesse, they will tax your computer if your dataset is large enough. This is the issue I ran into when I attempted to learn TensorFlow. I went through the first tutorials up until MNIST, and discovered that their digit recognition example takes about twenty minutes to run on my computer, which just will not do. My solution was to do more research into the open source neural network libraries, which seem to (like most other software), perform better than their enterprise counterparts. \n",
    "<br>\n",
    "<br>\n",
    "I found that the library Theano, used by Spotify and Torch, used by facebook have cult followings that make them superior to tensorflow. Theano, being a symbolic math language, was developed and is maintained by academics and offers superior functionality and expression to TensorFlow in my opinion. Torch is a well documented version of TensorFlow which also has a great neural network library. As an example of what Theano is capable of, check out this Spotify employee's open source <a href = \"http://benanne.github.io/2014/08/05/spotify-cnns.html\">Music Reccomendation</a> Neural Network.\n",
    "<br>\n",
    "<br>\n",
    "In addition to switching libraries, I found a way to accelerate my calculations on my GPU. Because my computer has a graphics card that is not integrated into the cpu, I am able to use NVIDIA's GPU wrapper library CUDA to speed up my programs. Theano and Torch were built on top of CUDA and is meant to perform seamlessly with GPU acceleration. As an added bonus, all of this functionality can be hooked by CPython within Ipython Notebook!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Theano Documentation and Citations</h5>\n",
    "<li>F. Bastien, P. Lamblin, R. Pascanu, J. Bergstra, I. Goodfellow, A. Bergeron, N. Bouchard, D. Warde-Farley and Y. Bengio. “Theano: new features and speed improvements”. NIPS 2012 deep learning workshop. (BibTex)</li>\n",
    "<li>J. Bergstra, O. Breuleux, F. Bastien, P. Lamblin, R. Pascanu, G. Desjardins, J. Turian, D. Warde-Farley and Y. Bengio. “Theano: A CPU and GPU Math Expression Compiler”. Proceedings of the Python for Scientific Computing Conference (SciPy) 2010. June 30 - July 3, Austin, TX (BibTeX)</li>\n",
    "<li><a href = \"http://deeplearning.net/software/theano/\">Documentation</a></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Testing and Verifying GPU Acceleration</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce 840M\n",
      "WARNING (theano.sandbox.cuda): Ignoring call to use(-1), GPU number 0 is already in use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Elemwise{exp,no_inplace}(<TensorType(float64, vector)>)]\n",
      "Looping 1000 times took 4.378400 seconds\n",
      "Result is [ 1.23178032  1.61879341  1.52278065 ...,  2.20771815  2.29967753\n",
      "  1.62323285]\n",
      "Used the cpu\n"
     ]
    }
   ],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"cpu\")\n",
    "config.floatX = 'float64'\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The example above is one I modified from the Theano Doc's to show the difference between using the GPU and CPU. Theano has a configuration file for settings you would like to be rather permanent, and also allows you to call those settings from within python. By setting theano.sandbox.cuda.use(\"cpu\"), I force the computer to do the calculations on the CPU, regardless of the priority device. Additionally, Theano like's its information to be in float32 format to increase speed. Here I forced config.floatX = 'float64'. As you can see, the code for this program ran in about 5 seconds.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 1.608439 seconds\n",
      "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761\n",
      "  1.62323296]\n",
      "Used the gpu\n",
      "gpu\n",
      "FAST_RUN\n"
     ]
    }
   ],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu\")\n",
    "config.floatX = 'float32'\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x), mode = 'FAST_RUN')\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')\n",
    "    \n",
    "print(theano.config.device)\n",
    "print(theano.config.mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>By forcing the theano.sandbox.cuda.use(\"gpu\"), config.floatX = 'float32', and mode = 'FAST_RUN', we can drastically speed up our calculations. As you can see, this program ran in under 2 seconds, about half to 3/4 as long as the previous example.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>In Practice</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Since I had some extra time over spring break, I decided to try and write a program that would take a picture of a handwritten digit, train a neural network on the MNIST Dataset, and offer a prediction of the handwritten digit at the end. Additionally, I wanted to do all of this with GPU acceleration, hosted on my Ipython Notebook Server. This meant gaining an in depth understanding of how Ipython uses dependencies, and how my computer uses python dist-packages. Through much trial, I compiled a python3 compatible version of OpenCV2, and linked it to the python dist-packages, allowing it to be used within Ipython. I had to do the same with theano, and cudaNN. The end result is a beautiful workflow that allows you to train neural networks, take pictures and do image manipulation, and use markdown all within your IDE, sped up by the GPU.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The MNIST Dataset is famously hosted on Yann Lecunn's website, and can be downloaded for free <a href = \"http://yann.lecun.com/exdb/mnist/\">here</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OpenCV Version 3.1.0\n",
      "Taking image...\n",
      "(480, 640)\n",
      "320.0 240.0\n",
      "event contains (320.0, 240.0)\n",
      "320 226.0\n",
      "(28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:139: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Capture Test Sample\n",
    "\n",
    "#Necessary Imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "#Verify that we are using opencv version 3\n",
    "print(\"Using OpenCV Version\",cv2.__version__)\n",
    "\n",
    "cmdstring = \"espeak 'Hello, Please hold a picture of a handwritten digit up to the webcam.'\"\n",
    "os.system(cmdstring)\n",
    "\n",
    "# Camera 0 is the integrated web cam on my netbook\n",
    "camera_port = 0\n",
    "\n",
    "#Let camera adjust for light levels\n",
    "ramp_frames = 30\n",
    "\n",
    "# Now we can initialize the camera capture object with the cv2.VideoCapture class.\n",
    "# All it needs is the index to a camera port.\n",
    "camera = cv2.VideoCapture(camera_port)\n",
    "\n",
    "# Captures a single image from the camera and returns it in PIL format\n",
    "cmdstring = \"espeak 'Please drag the rectangle over the handwritten digit. When you are satisfied with the center, click the red X to exit.'\"\n",
    "os.system(cmdstring)\n",
    "\n",
    "def get_image():\n",
    "#read is the easiest way to get a full image out of a VideoCapture object.\n",
    "    retval, im = camera.read()\n",
    "    return im\n",
    " \n",
    "# Ramp the camera - these frames will be discarded and are only used to allow v4l2\n",
    "# to adjust light levels, if necessary\n",
    "for i in range(ramp_frames):\n",
    "    temp = get_image()\n",
    "print(\"Taking image...\")\n",
    "\n",
    "# Take the actual image we want to keep\n",
    "capture = get_image()\n",
    "file = \"test_image.png\"\n",
    "\n",
    "# A nice feature of the imwrite method is that it will automatically choose the\n",
    "# correct format based on the file extension you provide. Convenient!\n",
    "cv2.imwrite(file, capture)\n",
    " \n",
    "# You'll want to release the camera, otherwise you won't be able to create a new\n",
    "# capture object until your script exits\n",
    "del(camera)\n",
    "\n",
    "#Create a class that will contain callbacks within our image.\n",
    "class DraggableRectangle:\n",
    "    #Initialize the rectangle\n",
    "    def __init__(self, rect):\n",
    "        self.rect = rect\n",
    "        self.press = None\n",
    "\n",
    "    #Connect mouse listener to rectangle\n",
    "    def connect(self):\n",
    "        'connect to all the events we need'\n",
    "        self.cidpress = self.rect.figure.canvas.mpl_connect(\n",
    "            'button_press_event', self.on_press)\n",
    "        self.cidrelease = self.rect.figure.canvas.mpl_connect(\n",
    "            'button_release_event', self.on_release)\n",
    "        self.cidmotion = self.rect.figure.canvas.mpl_connect(\n",
    "            'motion_notify_event', self.on_motion)\n",
    "\n",
    "    def on_press(self, event):\n",
    "        'on button press we will see if the mouse is over us and store some data'\n",
    "        if event.inaxes != self.rect.axes: return\n",
    "\n",
    "        contains, attrd = self.rect.contains(event)\n",
    "        if not contains: return\n",
    "        print ('event contains', self.rect.xy)\n",
    "        x0, y0 = self.rect.xy\n",
    "        self.press = x0, y0, event.xdata, event.ydata\n",
    "\n",
    "    def on_motion(self, event):\n",
    "        'on motion we will move the rect if the mouse is over us'\n",
    "        if self.press is None: return\n",
    "        if event.inaxes != self.rect.axes: return\n",
    "        x0, y0, xpress, ypress = self.press\n",
    "        dx = event.xdata - xpress\n",
    "        dy = event.ydata - ypress\n",
    "        self.rect.set_x(x0+dx)\n",
    "        self.rect.set_y(y0+dy)\n",
    "        self.rect.figure.canvas.draw()\n",
    "\n",
    "\n",
    "    def on_release(self, event):\n",
    "        'on release we reset the press data'\n",
    "        self.press = None\n",
    "        self.rect.figure.canvas.draw()\n",
    "        newClip.X, newClip.Y = event.x-14, event.y\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def disconnect(self):\n",
    "        'disconnect all the stored connection ids'\n",
    "        self.rect.figure.canvas.mpl_disconnect(self.cidpress)\n",
    "        self.rect.figure.canvas.mpl_disconnect(self.cidrelease)\n",
    "        self.rect.figure.canvas.mpl_disconnect(self.cidmotion)\n",
    "        \n",
    "#Clip object to store center points of full image\n",
    "class NewClip:\n",
    "     def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y \n",
    "    \n",
    "#Set our clip to the middle of the image    \n",
    "newClip = NewClip((640/2),(480/2))\n",
    "\n",
    "img = cv2.imread('test_image.png',0)\n",
    "print(img.shape)\n",
    "fig = plt.figure()\n",
    "\n",
    "#Display image with inverse grey scale...gray? make up your fucking mind english.\n",
    "plt.imshow(img, cmap = 'Greys')\n",
    "\n",
    "ax = plt.subplot()\n",
    "currentAxis = plt.gca()\n",
    "rect = Rectangle((newClip.X, newClip.Y), 28, 28,\n",
    "                      alpha=.5, facecolor='white')\n",
    "print(newClip.X, newClip.Y)\n",
    "currentAxis.add_patch(rect)\n",
    "dr = DraggableRectangle(rect)\n",
    "dr.connect()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Show center points\n",
    "print(newClip.X, newClip.Y)\n",
    "\n",
    "clip = img[((480.0 - newClip.Y) -14.0):((480.0 - newClip.Y) + 14.0), \n",
    "           ((newClip.X) - 14.0):((newClip.X) + 14.0)]\n",
    "\n",
    "#Verify that our clip is the correct dimension\n",
    "print(clip.shape)\n",
    "plt.imshow(clip, cmap = 'gray')\n",
    "plt.show()\n",
    "cmdstring = \"espeak 'If you are unsatisfied with the sample image, please restart the program.'\"\n",
    "os.system(cmdstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In the above program, I wrote a method to grab a clip from a gray scale image the size of the MNIST images. This allows me to create my own test data. I will not go into detail on how I wrote the opencv program, as the focus is on neural networks, and it is quite well documented. The speech library I am using is espeak, for Ubuntu.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(1, 784)\n",
      "[[ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.97333336  0.83999997\n",
      "   0.80000001  0.86000001  0.98000002  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.99333334  0.77999997  0.71333331\n",
      "   0.67333335  0.68000001  0.69999999  0.73333335  0.83999997  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.94        0.74000001  0.76666665\n",
      "   0.9066667   0.          0.          0.          0.95333332  0.81333333\n",
      "   0.78666669  0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.80000001\n",
      "   0.92666668  0.          0.          0.          0.          0.          0.\n",
      "   0.9066667   0.69999999  0.85333335  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.92000002\n",
      "   0.86666667  0.          0.          0.          0.          0.          0.\n",
      "   0.          0.97333336  0.66000003  0.80000001  0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.83999997  0.98000002  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.94        0.66000003  0.89999998  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.95333332  0.74000001  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.80000001  0.70666665  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.92000002  0.72666669  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.95999998  0.69333333  0.83333331  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.96666664  0.72000003  0.          0.          0.          0.          0.\n",
      "   0.          0.94        0.69999999  0.73333335  0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.77333331  0.92666668  0.          0.          0.          0.\n",
      "   0.82666665  0.68000001  0.70666665  0.97333336  0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.88666666  0.83999997  0.          0.          0.88666666\n",
      "   0.74000001  0.71333331  0.71333331  0.95999998  0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.81333333  0.74666667  0.71333331\n",
      "   0.66666669  0.69999999  0.83999997  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.91333336\n",
      "   0.88        0.94666666  0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu\")\n",
    "config.floatX = 'float32'\n",
    "cmdstring = \"espeak 'Converting the test image to M N I S T format.'\"\n",
    "os.system(cmdstring)\n",
    "# Uncomment to choose a new test image\n",
    "#cv2.imwrite('zero.png', clip)\n",
    "testArray = cv2.imread('zero.png', 0)\n",
    "plt.imshow(testArray, 'gray')\n",
    "plt.show()\n",
    "print(testArray.shape)\n",
    "def convert(image):\n",
    "    image2 = image.reshape((1, 784))\n",
    "    print(image2.shape)\n",
    "    for i in range(image2.size):\n",
    "        if image2[[0],[i]] >= 150:\n",
    "            image2[[0],[i]] = 0.\n",
    "    return image2\n",
    "testArray = convert(testArray)\n",
    "testArray = testArray/150\n",
    "testArray = numpy.asarray(testArray, dtype=theano.config.floatX)\n",
    "print(testArray)\n",
    "errorCheck = testArray.reshape((28,28))\n",
    "plt.imshow(errorCheck, 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The MNIST Data is stored in a very confusing packaging, so we need to convert the test clip into something our Neural Network will understand alongside the MNIST data. By reshaping the array to 1, 784 and using a threshhold function, we can replicate the black and white tensors stored in the pickle. Additionally, theano requires us to convert the data to float32 so this does not take forever.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmdstring = \"espeak 'Loading M N I S T dataset.'\"\n",
    "os.system(cmdstring)\n",
    "import gzip, numpy\n",
    "import pickle\n",
    "\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = pickle.load(f, encoding='iso-8859-1')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Function from the theano docs to unpack MNIST Data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmdstring = \"espeak 'Storing variables to G P U.'\"\n",
    "os.system(cmdstring)\n",
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import time\n",
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu\")\n",
    "def shared_dataset(data_xy):\n",
    "    \"\"\" Function that loads the dataset into shared variables\n",
    "\n",
    "    The reason we store our dataset in shared variables is to allow\n",
    "    Theano to copy it into the GPU memory (when code is run on GPU).\n",
    "    Since copying data into the GPU is slow, copying a minibatch everytime\n",
    "    is needed (the default behaviour if the data is not in a shared\n",
    "    variable) would lead to a large decrease in performance.\n",
    "    \"\"\"\n",
    "    data_x, data_y = data_xy\n",
    "    shared_x = theano.shared(numpy.asarray(data_x, dtype=theano.config.floatX))\n",
    "    shared_y = theano.shared(numpy.asarray(data_y, dtype=theano.config.floatX))\n",
    "    # When storing data on the GPU it has to be stored as floats\n",
    "    # therefore we will store the labels as ``floatX`` as well\n",
    "    # (``shared_y`` does exactly that). But during our computations\n",
    "    # we need them as ints (we use labels as index, and if they are\n",
    "    # floats it doesn't make sense) therefore instead of returning\n",
    "    # ``shared_y`` we will have to cast it to int. This little hack\n",
    "    # lets us get around this issue\n",
    "    return shared_x, T.cast(shared_y, 'int32')\n",
    "\n",
    "test_set_x, test_set_y = shared_dataset(test_set)\n",
    "valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
    "train_set_x, train_set_y = shared_dataset(train_set)\n",
    "\n",
    "batch_size = 500    # size of the minibatch\n",
    "\n",
    "# accessing the third minibatch of the training set\n",
    "\n",
    "data  = train_set_x[2 * batch_size: 3 * batch_size]\n",
    "label = train_set_y[2 * batch_size: 3 * batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Function from the theano docs to similarly store the MNIST Data in shared memory on the GPU, and split between test and training batches.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "... building the model\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "... training the model\n",
      "epoch 1, minibatch 83/83, validation error 12.458333 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 1, minibatch 83/83, test error of best model 12.375000 %\n",
      "epoch 2, minibatch 83/83, validation error 11.010417 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 2, minibatch 83/83, test error of best model 10.958333 %\n",
      "epoch 3, minibatch 83/83, validation error 10.312500 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 3, minibatch 83/83, test error of best model 10.312500 %\n",
      "epoch 4, minibatch 83/83, validation error 9.875000 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 4, minibatch 83/83, test error of best model 9.833333 %\n",
      "epoch 5, minibatch 83/83, validation error 9.562500 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 5, minibatch 83/83, test error of best model 9.479167 %\n",
      "epoch 6, minibatch 83/83, validation error 9.322917 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 6, minibatch 83/83, test error of best model 9.291667 %\n",
      "epoch 7, minibatch 83/83, validation error 9.187500 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 7, minibatch 83/83, test error of best model 9.000000 %\n",
      "epoch 8, minibatch 83/83, validation error 8.989583 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 8, minibatch 83/83, test error of best model 8.958333 %\n",
      "epoch 9, minibatch 83/83, validation error 8.937500 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 9, minibatch 83/83, test error of best model 8.812500 %\n",
      "epoch 10, minibatch 83/83, validation error 8.750000 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 10, minibatch 83/83, test error of best model 8.666667 %\n",
      "epoch 11, minibatch 83/83, validation error 8.666667 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 11, minibatch 83/83, test error of best model 8.520833 %\n",
      "epoch 12, minibatch 83/83, validation error 8.583333 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 12, minibatch 83/83, test error of best model 8.416667 %\n",
      "epoch 13, minibatch 83/83, validation error 8.489583 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 13, minibatch 83/83, test error of best model 8.291667 %\n",
      "epoch 14, minibatch 83/83, validation error 8.427083 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 14, minibatch 83/83, test error of best model 8.281250 %\n",
      "epoch 15, minibatch 83/83, validation error 8.354167 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 15, minibatch 83/83, test error of best model 8.270833 %\n",
      "epoch 16, minibatch 83/83, validation error 8.302083 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 16, minibatch 83/83, test error of best model 8.239583 %\n",
      "epoch 17, minibatch 83/83, validation error 8.250000 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 17, minibatch 83/83, test error of best model 8.177083 %\n",
      "epoch 18, minibatch 83/83, validation error 8.229167 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 18, minibatch 83/83, test error of best model 8.062500 %\n",
      "epoch 19, minibatch 83/83, validation error 8.260417 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 20, minibatch 83/83, validation error 8.260417 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 21, minibatch 83/83, validation error 8.208333 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 21, minibatch 83/83, test error of best model 7.947917 %\n",
      "epoch 22, minibatch 83/83, validation error 8.187500 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 22, minibatch 83/83, test error of best model 7.927083 %\n",
      "epoch 23, minibatch 83/83, validation error 8.156250 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 23, minibatch 83/83, test error of best model 7.958333 %\n",
      "epoch 24, minibatch 83/83, validation error 8.114583 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 24, minibatch 83/83, test error of best model 7.947917 %\n",
      "epoch 25, minibatch 83/83, validation error 8.093750 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 25, minibatch 83/83, test error of best model 7.947917 %\n",
      "epoch 26, minibatch 83/83, validation error 8.104167 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 27, minibatch 83/83, validation error 8.104167 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 28, minibatch 83/83, validation error 8.052083 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 28, minibatch 83/83, test error of best model 7.843750 %\n",
      "epoch 29, minibatch 83/83, validation error 8.052083 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 30, minibatch 83/83, validation error 8.031250 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 30, minibatch 83/83, test error of best model 7.843750 %\n",
      "epoch 31, minibatch 83/83, validation error 8.010417 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 31, minibatch 83/83, test error of best model 7.833333 %\n",
      "epoch 32, minibatch 83/83, validation error 7.979167 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 32, minibatch 83/83, test error of best model 7.812500 %\n",
      "epoch 33, minibatch 83/83, validation error 7.947917 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 33, minibatch 83/83, test error of best model 7.739583 %\n",
      "epoch 34, minibatch 83/83, validation error 7.875000 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 34, minibatch 83/83, test error of best model 7.729167 %\n",
      "epoch 35, minibatch 83/83, validation error 7.885417 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 36, minibatch 83/83, validation error 7.843750 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 36, minibatch 83/83, test error of best model 7.697917 %\n",
      "epoch 37, minibatch 83/83, validation error 7.802083 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 37, minibatch 83/83, test error of best model 7.635417 %\n",
      "epoch 38, minibatch 83/83, validation error 7.812500 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 39, minibatch 83/83, validation error 7.812500 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 40, minibatch 83/83, validation error 7.822917 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 41, minibatch 83/83, validation error 7.791667 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 41, minibatch 83/83, test error of best model 7.625000 %\n",
      "epoch 42, minibatch 83/83, validation error 7.770833 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 42, minibatch 83/83, test error of best model 7.614583 %\n",
      "epoch 43, minibatch 83/83, validation error 7.750000 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 43, minibatch 83/83, test error of best model 7.593750 %\n",
      "epoch 44, minibatch 83/83, validation error 7.739583 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 44, minibatch 83/83, test error of best model 7.593750 %\n",
      "epoch 45, minibatch 83/83, validation error 7.739583 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 46, minibatch 83/83, validation error 7.739583 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 47, minibatch 83/83, validation error 7.739583 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 48, minibatch 83/83, validation error 7.708333 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 48, minibatch 83/83, test error of best model 7.583333 %\n",
      "epoch 49, minibatch 83/83, validation error 7.677083 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 49, minibatch 83/83, test error of best model 7.572917 %\n",
      "epoch 50, minibatch 83/83, validation error 7.677083 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 51, minibatch 83/83, validation error 7.677083 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 52, minibatch 83/83, validation error 7.656250 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 52, minibatch 83/83, test error of best model 7.541667 %\n",
      "epoch 53, minibatch 83/83, validation error 7.656250 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 54, minibatch 83/83, validation error 7.635417 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 54, minibatch 83/83, test error of best model 7.520833 %\n",
      "epoch 55, minibatch 83/83, validation error 7.635417 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 56, minibatch 83/83, validation error 7.635417 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 57, minibatch 83/83, validation error 7.604167 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 57, minibatch 83/83, test error of best model 7.489583 %\n",
      "epoch 58, minibatch 83/83, validation error 7.583333 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 58, minibatch 83/83, test error of best model 7.458333 %\n",
      "epoch 59, minibatch 83/83, validation error 7.572917 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 59, minibatch 83/83, test error of best model 7.468750 %\n",
      "epoch 60, minibatch 83/83, validation error 7.572917 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 61, minibatch 83/83, validation error 7.583333 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 62, minibatch 83/83, validation error 7.572917 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 62, minibatch 83/83, test error of best model 7.520833 %\n",
      "epoch 63, minibatch 83/83, validation error 7.562500 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 63, minibatch 83/83, test error of best model 7.510417 %\n",
      "epoch 64, minibatch 83/83, validation error 7.572917 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 65, minibatch 83/83, validation error 7.562500 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 66, minibatch 83/83, validation error 7.552083 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 66, minibatch 83/83, test error of best model 7.520833 %\n",
      "epoch 67, minibatch 83/83, validation error 7.552083 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 68, minibatch 83/83, validation error 7.531250 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 68, minibatch 83/83, test error of best model 7.520833 %\n",
      "epoch 69, minibatch 83/83, validation error 7.531250 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 70, minibatch 83/83, validation error 7.510417 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 70, minibatch 83/83, test error of best model 7.500000 %\n",
      "epoch 71, minibatch 83/83, validation error 7.520833 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 72, minibatch 83/83, validation error 7.510417 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "epoch 73, minibatch 83/83, validation error 7.500000 %\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n",
      "     epoch 73, minibatch 83/83, test error of best model 7.489583 %\n",
      "Optimization complete with best validation score of 7.500000 %,with test performance 7.489583 %\n",
      "The code run for 74 epochs, with 3.069161 epochs/sec\n",
      "float32\n",
      "FAST_RUN\n",
      "gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code for file __file__ ran for 24.1s\n"
     ]
    }
   ],
   "source": [
    "cmdstring = \"espeak 'Training Neural Network on 50000 handwritten characters.'\"\n",
    "os.system(cmdstring)\n",
    "#Teach our network to recognize handwritten digits\n",
    "\n",
    "\"\"\"\n",
    "This tutorial introduces logistic regression using Theano and stochastic\n",
    "gradient descent.\n",
    "\n",
    "Logistic regression is a probabilistic, linear classifier. It is parametrized\n",
    "by a weight matrix :math:`W` and a bias vector :math:`b`. Classification is\n",
    "done by projecting data points onto a set of hyperplanes, the distance to\n",
    "which is used to determine a class membership probability.\n",
    "\n",
    "Mathematically, this can be written as:\n",
    "\n",
    ".. math::\n",
    "  P(Y=i|x, W,b) &= softmax_i(W x + b) \\\\\n",
    "                &= \\frac {e^{W_i x + b_i}} {\\sum_j e^{W_j x + b_j}}\n",
    "\n",
    "\n",
    "The output of the model or prediction is then done by taking the argmax of\n",
    "the vector whose i'th element is P(Y=i|x).\n",
    "\n",
    ".. math::\n",
    "\n",
    "  y_{pred} = argmax_i P(Y=i|x,W,b)\n",
    "\n",
    "\n",
    "This tutorial presents a stochastic gradient descent optimization method\n",
    "suitable for large datasets.\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "    - textbooks: \"Pattern Recognition and Machine Learning\" -\n",
    "                 Christopher M. Bishop, section 4.3.2\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "__docformat__ = 'restructedtext en'\n",
    "\n",
    "import six.moves.cPickle as pickle\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "class LogisticRegression(object):\n",
    "    \"\"\"Multi-class Logistic Regression Class\n",
    "\n",
    "    The logistic regression is fully described by a weight matrix :math:`W`\n",
    "    and bias vector :math:`b`. Classification is done by projecting data\n",
    "    points onto a set of hyperplanes, the distance to which is used to\n",
    "    determine a class membership probability.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input, n_in, n_out):\n",
    "        \"\"\" Initialize the parameters of the logistic regression\n",
    "\n",
    "        :type input: theano.tensor.TensorType\n",
    "        :param input: symbolic variable that describes the input of the\n",
    "                      architecture (one minibatch)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: number of input units, the dimension of the space in\n",
    "                     which the datapoints lie\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of output units, the dimension of the space in\n",
    "                      which the labels lie\n",
    "\n",
    "        \"\"\"\n",
    "        # start-snippet-1\n",
    "        # initialize with 0 the weights W as a matrix of shape (n_in, n_out)\n",
    "        self.W = theano.shared(\n",
    "            value=numpy.zeros(\n",
    "                (n_in, n_out),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            name='W',\n",
    "            borrow=True\n",
    "        )\n",
    "        # initialize the biases b as a vector of n_out 0s\n",
    "        self.b = theano.shared(\n",
    "            value=numpy.zeros(\n",
    "                (n_out,),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            name='b',\n",
    "            borrow=True\n",
    "        )\n",
    "        print(theano.config.floatX)\n",
    "        print(theano.config.mode)\n",
    "        print(theano.config.device)\n",
    "        # symbolic expression for computing the matrix of class-membership\n",
    "        # probabilities\n",
    "        # Where:\n",
    "        # W is a matrix where column-k represent the separation hyperplane for\n",
    "        # class-k\n",
    "        # x is a matrix where row-j  represents input training sample-j\n",
    "        # b is a vector where element-k represent the free parameter of\n",
    "        # hyperplane-k\n",
    "        self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)\n",
    "\n",
    "        # symbolic description of how to compute prediction as class whose\n",
    "        # probability is maximal\n",
    "        self.y_pred = T.argmax(self.p_y_given_x, axis=1)\n",
    "        # end-snippet-1\n",
    "\n",
    "        # parameters of the model\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "        # keep track of model input\n",
    "        self.input = input\n",
    "\n",
    "    def negative_log_likelihood(self, y):\n",
    "        \"\"\"Return the mean of the negative log-likelihood of the prediction\n",
    "        of this model under a given target distribution.\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            \\frac{1}{|\\mathcal{D}|} \\mathcal{L} (\\theta=\\{W,b\\}, \\mathcal{D}) =\n",
    "            \\frac{1}{|\\mathcal{D}|} \\sum_{i=0}^{|\\mathcal{D}|}\n",
    "                \\log(P(Y=y^{(i)}|x^{(i)}, W,b)) \\\\\n",
    "            \\ell (\\theta=\\{W,b\\}, \\mathcal{D})\n",
    "\n",
    "        :type y: theano.tensor.TensorType\n",
    "        :param y: corresponds to a vector that gives for each example the\n",
    "                  correct label\n",
    "\n",
    "        Note: we use the mean instead of the sum so that\n",
    "              the learning rate is less dependent on the batch size\n",
    "        \"\"\"\n",
    "        # start-snippet-2\n",
    "        # y.shape[0] is (symbolically) the number of rows in y, i.e.,\n",
    "        # number of examples (call it n) in the minibatch\n",
    "        # T.arange(y.shape[0]) is a symbolic vector which will contain\n",
    "        # [0,1,2,... n-1] T.log(self.p_y_given_x) is a matrix of\n",
    "        # Log-Probabilities (call it LP) with one row per example and\n",
    "        # one column per class LP[T.arange(y.shape[0]),y] is a vector\n",
    "        # v containing [LP[0,y[0]], LP[1,y[1]], LP[2,y[2]], ...,\n",
    "        # LP[n-1,y[n-1]]] and T.mean(LP[T.arange(y.shape[0]),y]) is\n",
    "        # the mean (across minibatch examples) of the elements in v,\n",
    "        # i.e., the mean log-likelihood across the minibatch.\n",
    "        return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])\n",
    "        # end-snippet-2\n",
    "\n",
    "    def errors(self, y):\n",
    "        \"\"\"Return a float representing the number of errors in the minibatch\n",
    "        over the total number of examples of the minibatch ; zero one\n",
    "        loss over the size of the minibatch\n",
    "\n",
    "        :type y: theano.tensor.TensorType\n",
    "        :param y: corresponds to a vector that gives for each example the\n",
    "                  correct label\n",
    "        \"\"\"\n",
    "\n",
    "        # check if y has same dimension of y_pred\n",
    "        if y.ndim != self.y_pred.ndim:\n",
    "            raise TypeError(\n",
    "                'y should have the same shape as self.y_pred',\n",
    "                ('y', y.type, 'y_pred', self.y_pred.type)\n",
    "            )\n",
    "        # check if y is of the correct datatype\n",
    "        if y.dtype.startswith('int'):\n",
    "            # the T.neq operator returns a vector of 0s and 1s, where 1\n",
    "            # represents a mistake in prediction\n",
    "            return T.mean(T.neq(self.y_pred, y))\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "\n",
    "def load_data(dataset):\n",
    "    ''' Loads the dataset\n",
    "\n",
    "    :type dataset: string\n",
    "    :param dataset: the path to the dataset (here MNIST)\n",
    "    '''\n",
    "\n",
    "    #############\n",
    "    # LOAD DATA #\n",
    "    #############\n",
    "\n",
    "    # Download the MNIST dataset if it is not present\n",
    "    data_dir, data_file = os.path.split(dataset)\n",
    "    if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "        # Check if dataset is in the data directory.\n",
    "        new_path = os.path.join(\n",
    "            os.path.split(__file__)[0],\n",
    "            \"..\",\n",
    "            \"data\",\n",
    "            dataset\n",
    "        )\n",
    "        if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "            dataset = new_path\n",
    "\n",
    "    if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "        from six.moves import urllib\n",
    "        origin = (\n",
    "            'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
    "        )\n",
    "        print('Downloading data from %s' % origin)\n",
    "        urllib.request.urlretrieve(origin, dataset)\n",
    "\n",
    "    print('... loading data')\n",
    "\n",
    "    # Load the dataset\n",
    "    with gzip.open(dataset, 'rb') as f:\n",
    "        try:\n",
    "            train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "        except:\n",
    "            train_set, valid_set, test_set = pickle.load(f)\n",
    "    # train_set, valid_set, test_set format: tuple(input, target)\n",
    "    # input is a numpy.ndarray of 2 dimensions (a matrix)\n",
    "    # where each row corresponds to an example. target is a\n",
    "    # numpy.ndarray of 1 dimension (vector) that has the same length as\n",
    "    # the number of rows in the input. It should give the target\n",
    "    # to the example with the same index in the input.\n",
    "\n",
    "    def shared_dataset(data_xy, borrow=True):\n",
    "        \"\"\" Function that loads the dataset into shared variables\n",
    "\n",
    "        The reason we store our dataset in shared variables is to allow\n",
    "        Theano to copy it into the GPU memory (when code is run on GPU).\n",
    "        Since copying data into the GPU is slow, copying a minibatch everytime\n",
    "        is needed (the default behaviour if the data is not in a shared\n",
    "        variable) would lead to a large decrease in performance.\n",
    "        \"\"\"\n",
    "        data_x, data_y = data_xy\n",
    "        shared_x = theano.shared(numpy.asarray(data_x,\n",
    "                                               dtype=theano.config.floatX),\n",
    "                                 borrow=borrow)\n",
    "        shared_y = theano.shared(numpy.asarray(data_y,\n",
    "                                               dtype=theano.config.floatX),\n",
    "                                 borrow=borrow)\n",
    "        # When storing data on the GPU it has to be stored as floats\n",
    "        # therefore we will store the labels as ``floatX`` as well\n",
    "        # (``shared_y`` does exactly that). But during our computations\n",
    "        # we need them as ints (we use labels as index, and if they are\n",
    "        # floats it doesn't make sense) therefore instead of returning\n",
    "        # ``shared_y`` we will have to cast it to int. This little hack\n",
    "        # lets ous get around this issue\n",
    "        return shared_x, T.cast(shared_y, 'int32')\n",
    "\n",
    "    test_set_x, test_set_y = shared_dataset(test_set)\n",
    "    valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
    "    train_set_x, train_set_y = shared_dataset(train_set)\n",
    "\n",
    "    rval = [(train_set_x, train_set_y), (valid_set_x, valid_set_y),\n",
    "            (test_set_x, test_set_y)]\n",
    "    return rval\n",
    "\n",
    "\n",
    "def sgd_optimization_mnist(learning_rate=0.13, n_epochs=1000,\n",
    "                           dataset='mnist.pkl.gz',\n",
    "                           batch_size=600):\n",
    "    \"\"\"\n",
    "    Demonstrate stochastic gradient descent optimization of a log-linear\n",
    "    model\n",
    "\n",
    "    This is demonstrated on MNIST.\n",
    "\n",
    "    :type learning_rate: float\n",
    "    :param learning_rate: learning rate used (factor for the stochastic\n",
    "                          gradient)\n",
    "\n",
    "    :type n_epochs: int\n",
    "    :param n_epochs: maximal number of epochs to run the optimizer\n",
    "\n",
    "    :type dataset: string\n",
    "    :param dataset: the path of the MNIST dataset file from\n",
    "                 http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz\n",
    "\n",
    "    \"\"\"\n",
    "    datasets = load_data(dataset)\n",
    "\n",
    "    train_set_x, train_set_y = datasets[0]\n",
    "    valid_set_x, valid_set_y = datasets[1]\n",
    "    test_set_x, test_set_y = datasets[2]\n",
    "\n",
    "    # compute number of minibatches for training, validation and testing\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "    n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "    n_test_batches = test_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "\n",
    "    ######################\n",
    "    # BUILD ACTUAL MODEL #\n",
    "    ######################\n",
    "    print('... building the model')\n",
    "\n",
    "    # allocate symbolic variables for the data\n",
    "    index = T.lscalar()  # index to a [mini]batch\n",
    "\n",
    "    # generate symbolic variables for input (x and y represent a\n",
    "    # minibatch)\n",
    "    x = T.matrix('x')  # data, presented as rasterized images\n",
    "    y = T.ivector('y')  # labels, presented as 1D vector of [int] labels\n",
    "\n",
    "    # construct the logistic regression class\n",
    "    # Each MNIST image has size 28*28\n",
    "    classifier = LogisticRegression(input=x, n_in=28 * 28, n_out=10)\n",
    "\n",
    "    # the cost we minimize during training is the negative log likelihood of\n",
    "    # the model in symbolic format\n",
    "    cost = classifier.negative_log_likelihood(y)\n",
    "\n",
    "    # compiling a Theano function that computes the mistakes that are made by\n",
    "    # the model on a minibatch\n",
    "    test_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.errors(y),\n",
    "        givens={\n",
    "            x: test_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: test_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    ,mode = \"FAST_RUN\")\n",
    "\n",
    "    validate_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.errors(y),\n",
    "        givens={\n",
    "            x: valid_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: valid_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    ,mode = \"FAST_RUN\")\n",
    "\n",
    "    # compute the gradient of cost with respect to theta = (W,b)\n",
    "    g_W = T.grad(cost=cost, wrt=classifier.W)\n",
    "    g_b = T.grad(cost=cost, wrt=classifier.b)\n",
    "\n",
    "    # start-snippet-3\n",
    "    # specify how to update the parameters of the model as a list of\n",
    "    # (variable, update expression) pairs.\n",
    "    updates = [(classifier.W, classifier.W - learning_rate * g_W),\n",
    "               (classifier.b, classifier.b - learning_rate * g_b)]\n",
    "\n",
    "    # compiling a Theano function `train_model` that returns the cost, but in\n",
    "    # the same time updates the parameter of the model based on the rules\n",
    "    # defined in `updates`\n",
    "    train_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: train_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    , mode = \"FAST_RUN\")\n",
    "    print(theano.config.floatX)\n",
    "    print(theano.config.mode)\n",
    "    print(theano.config.device)\n",
    "    # end-snippet-3\n",
    "\n",
    "    ###############\n",
    "    # TRAIN MODEL #\n",
    "    ###############\n",
    "    print('... training the model')\n",
    "    # early-stopping parameters\n",
    "    patience = 5000  # look as this many examples regardless\n",
    "    patience_increase = 2  # wait this much longer when a new best is\n",
    "                                  # found\n",
    "    improvement_threshold = 0.995  # a relative improvement of this much is\n",
    "                                  # considered significant\n",
    "    validation_frequency = min(n_train_batches, patience // 2)\n",
    "                                  # go through this many\n",
    "                                  # minibatche before checking the network\n",
    "                                  # on the validation set; in this case we\n",
    "                                  # check every epoch\n",
    "\n",
    "    best_validation_loss = numpy.inf\n",
    "    test_score = 0.\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    done_looping = False\n",
    "    epoch = 0\n",
    "    while (epoch < n_epochs) and (not done_looping):\n",
    "        epoch = epoch + 1\n",
    "        for minibatch_index in range(n_train_batches):\n",
    "\n",
    "            minibatch_avg_cost = train_model(minibatch_index)\n",
    "            # iteration number\n",
    "            iter = (epoch - 1) * n_train_batches + minibatch_index\n",
    "\n",
    "            if (iter + 1) % validation_frequency == 0:\n",
    "                # compute zero-one loss on validation set\n",
    "                validation_losses = [validate_model(i)\n",
    "                                     for i in range(n_valid_batches)]\n",
    "                this_validation_loss = numpy.mean(validation_losses)\n",
    "\n",
    "                print(\n",
    "                    'epoch %i, minibatch %i/%i, validation error %f %%' %\n",
    "                    (\n",
    "                        epoch,\n",
    "                        minibatch_index + 1,\n",
    "                        n_train_batches,\n",
    "                        this_validation_loss * 100.\n",
    "                    )\n",
    "                )\n",
    "                print(theano.config.floatX)\n",
    "                print(theano.config.mode)\n",
    "                print(theano.config.device)\n",
    "                # if we got the best validation score until now\n",
    "                if this_validation_loss < best_validation_loss:\n",
    "                    #improve patience if loss improvement is good enough\n",
    "                    if this_validation_loss < best_validation_loss *  \\\n",
    "                       improvement_threshold:\n",
    "                        patience = max(patience, iter * patience_increase)\n",
    "\n",
    "                    best_validation_loss = this_validation_loss\n",
    "                    # test it on the test set\n",
    "\n",
    "                    test_losses = [test_model(i)\n",
    "                                   for i in range(n_test_batches)]\n",
    "                    test_score = numpy.mean(test_losses)\n",
    "\n",
    "                    print(\n",
    "                        (\n",
    "                            '     epoch %i, minibatch %i/%i, test error of'\n",
    "                            ' best model %f %%'\n",
    "                        ) %\n",
    "                        (\n",
    "                            epoch,\n",
    "                            minibatch_index + 1,\n",
    "                            n_train_batches,\n",
    "                            test_score * 100.\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    # save the best model\n",
    "                    with open('best_model.pkl', 'wb') as f:\n",
    "                        pickle.dump(classifier, f)\n",
    "\n",
    "            if patience <= iter:\n",
    "                done_looping = True\n",
    "                break\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "    print(\n",
    "        (\n",
    "            'Optimization complete with best validation score of %f %%,'\n",
    "            'with test performance %f %%'\n",
    "        )\n",
    "        % (best_validation_loss * 100., test_score * 100.)\n",
    "    )\n",
    "    print('The code run for %d epochs, with %f epochs/sec' % (\n",
    "        epoch, 1. * epoch / (end_time - start_time)))\n",
    "    print(('The code for file ' +\n",
    "           os.path.split('__file__')[1] +\n",
    "           ' ran for %.1fs' % ((end_time - start_time))), file=sys.stderr)\n",
    "\n",
    "sgd_optimization_mnist()\n",
    "print(theano.config.floatX)\n",
    "print(theano.config.mode)\n",
    "print(theano.config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Above is the Neural Network I plan to modify next week to use convolutional pooling. As you can see, the code uses the GPU, and runs in under 25 seconds, which is quite reasonable for 50,000 data inputs!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "Predicted values for the first 10 examples in test set:\n",
      "[7 2 1 0 4 1 4 9 6 9]\n",
      "Predicted value for test sample:\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "cmdstring = \"espeak 'Evaluating model and predicting label for test image.'\"\n",
    "os.system(cmdstring)\n",
    "def predict():\n",
    "    \"\"\"\n",
    "    An example of how to load a trained model and use it\n",
    "    to predict labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # load the saved model\n",
    "    classifier = pickle.load(open('best_model.pkl', 'rb'))\n",
    "    # compile a predictor function\n",
    "    predict_model = theano.function(\n",
    "        inputs=[classifier.input],\n",
    "        outputs=classifier.y_pred)\n",
    "\n",
    "    # We can test it on some examples from test set\n",
    "    dataset='mnist.pkl.gz'\n",
    "    datasets = load_data(dataset)\n",
    "    test_set_x, test_set_y = datasets[2]\n",
    "    test_set_x = test_set_x.get_value()\n",
    "    predicted_values = predict_model(test_set_x[:10])\n",
    "    print(\"Predicted values for the first 10 examples in test set:\")\n",
    "    print(predicted_values)\n",
    "    predicted_values2 = predict_model(testArray)\n",
    "    print(\"Predicted value for test sample:\")\n",
    "    print(predicted_values2)\n",
    "    errorCheck = testArray.reshape((28,28))\n",
    "    plt.imshow(errorCheck, 'gray')\n",
    "    plt.show()\n",
    "    errorCheck2 = test_set_x[3].reshape((28,28))\n",
    "    plt.imshow(errorCheck2, 'gray')\n",
    "    plt.show()\n",
    "\n",
    "predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This function checks our test image, and the first ten provided test images againste the neural network's best epoch, or training dataset. As you can see, the program is correctly recognizing the provided data, but incorrectly categorizing my test image. I believe this is due to the small size of the clips (it makes it hard to get a perfectly centered image), and my threshholding function. Because the data are 1d arrays, uniformity is imperative. One way to account for this uniformity is to use what is called pooling on your image. Pooling is breaking the image down into different sections like our visual cortex does. This helps the neural network learn even if the images are off center or at an angle or rotated.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
